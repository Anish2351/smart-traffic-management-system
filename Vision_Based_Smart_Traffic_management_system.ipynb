{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Vision Based Smart Traffic management system.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm8ZgcsMdjar"
      },
      "source": [
        "### Set the current directory with the Location Yolo Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ourj9WDaefby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa13aea-cba1-400c-8263-f6d532bb144b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sjbOnuI9USe"
      },
      "source": [
        "Download YOLO Weight Files and Other Required files from https://www.kaggle.com/valentynsichkar/yolo-coco-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrb9hlzcgBGn",
        "outputId": "e7f8b846-a652-4ab7-a40f-5bd29ba1a3f1"
      },
      "source": [
        "%cd /content/drive/MyDrive/Kaggle/YOLO\\ weights\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "# !wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Kaggle/YOLO weights\n",
            "--2020-11-21 11:19:04--  https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg              [ <=>                ] 261.41K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-11-21 11:19:04 (9.03 MB/s) - ‘yolov3.cfg’ saved [267686]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bj3hBks9hez"
      },
      "source": [
        "Set the Path to the folder containing YOLO Weight Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1rWj5i_dja0"
      },
      "source": [
        "model_path='/content/drive/MyDrive/Kaggle/YOLO weights'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5SQRcgydja1"
      },
      "source": [
        "### Set the Threshold for Confidence filter Weak Detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tMJqNpldja1"
      },
      "source": [
        "min_COnfidence=0.5\n",
        "NMS_Thres=0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYoOkgTCdja1"
      },
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0c-VPn4dja1"
      },
      "source": [
        "### We Create a function to Detect Features we want, We can extract more features as well which are avilable in coco.names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt0IZs_rdja2"
      },
      "source": [
        "def detectFeatures(frame, net, ln, bicycleIndx=0, carIndx=0, motorbikeIndx=0, busIndx=0, truckIndx=0):\n",
        "    #Getting Height, Width of the current frame\n",
        "    (H,W)=frame.shape[:2]\n",
        "    #We'll store out predicitons with it's details such as confidence, bounding box points in results\n",
        "    results=[]\n",
        "    #Creating a blob of current frame\n",
        "    blob=cv2.dnn.blobFromImage(frame, 1/255.0,(416,416), swapRB=True, crop=False)\n",
        "    #Giving the blob as input to our model to process this frame\n",
        "    net.setInput(blob)\n",
        "    #Getting the output of our Model which contains predictions\n",
        "    layerOutputs=net.forward(ln)\n",
        "    #We'll Stores the bounding box co-ordinates, confidences, ID which corresponds to object it is in these for our predictions\n",
        "    boxes=[]\n",
        "    confidences=[]\n",
        "    classIDs=[]\n",
        "    #Iterate though our outputs and each detection in each output\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            #Extract Confidence for each detection and it's ID for item it corresponds to\n",
        "            scores=detection[5:]\n",
        "            classID=np.argmax(scores)\n",
        "            confidence=scores[classID]\n",
        "            #We just want Bicycles, Cars, Bikes, Trucks and Buses to be detected\n",
        "            if (classID==bicycleIndx or classID==carIndx or classID==motorbikeIndx or classID==busIndx or classID==truckIndx) and confidence>min_COnfidence:\n",
        "                #Get the boundary box co-ordinates for our Detectection\n",
        "                box=detection[0:4]*np.array([W,H,W,H])\n",
        "                (centerX, centerY, width, height)=box.astype('int')\n",
        "                x=int(centerX-(width/2))\n",
        "                y=int(centerY-(height/2))\n",
        "                #Save these co-ordinates, confidence, ID of item number in the lists we initialized\n",
        "                boxes.append([x,y,int(width),int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "                classIDs.append(classID)\n",
        "    #Applying Non-Max Suppression to remove extra Bounding Boxes\n",
        "    indxs=cv2.dnn.NMSBoxes(boxes, confidences, min_COnfidence, NMS_Thres)\n",
        "    #Storing Final Detection's features in results\n",
        "    if len(indxs)>0:\n",
        "        for i in indxs.flatten():\n",
        "            (x,y)=(boxes[i][0], boxes[i][1])\n",
        "            (w,h)=(boxes[i][2], boxes[i][3])\n",
        "            r=(confidences[i], (x,y,x+w,y+h),classIDs[i])\n",
        "            results.append(r)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmf9RcDndja3"
      },
      "source": [
        "import numpy as np\n",
        "import imutils\n",
        "import os\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ75L7X7dja3"
      },
      "source": [
        "labelsPath='/content/YOLO weights/coco.names'\n",
        "labels=open(labelsPath).read().strip().split('\\n')\n",
        "weightPaths='/content/YOLO weights/yolov3.weights'\n",
        "configPath='/content/YOLO weights/yolov3.cfg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ptZBrazdja4"
      },
      "source": [
        "### Creating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpbqWyoTdja4"
      },
      "source": [
        "net=cv2.dnn.readNetFromDarknet(configPath, weightPaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CopXV1_mNbH"
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb8_5CdR90fq"
      },
      "source": [
        "I've also shared the code for Training of the Emergency Vehicles Classifier in this repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h08HpOC6-ldD"
      },
      "source": [
        "#### You can also download this Classifier's Weights files from here: \n",
        "https://drive.google.com/file/d/1-R6dkaTLXHB1Yyn1GH7LX9-Hpz5Mjx-z/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxVCpGE5maBf"
      },
      "source": [
        "emergencyModel=load_learner('/content/EmergencyVehicleClassificationFastAI','emergency_vehicles.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYFBY0Wdja5"
      },
      "source": [
        "### Giving the Input Video to process and output Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkXJnrAJdja5",
        "outputId": "353519be-b1d0-4587-c5c4-16c0ecad7f03"
      },
      "source": [
        "%cd /content/\n",
        "inp='/content/Transportation - Traffic Monitoring in a section (AI).mp4'\n",
        "output='/content/output1.avi'\n",
        "display=0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB-G6Yz3dja6"
      },
      "source": [
        "ln=net.getLayerNames()\n",
        "ln=[ln[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
        "vs=cv2.VideoCapture(inp)\n",
        "writer=None\n",
        "fps=vs.get(cv2.CAP_PROP_FPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWhrmZicxW0o"
      },
      "source": [
        "tempPath='/content/EmergencyVehicleClassificationFastAI/1.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az6c_fhjdja6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84cfd016-a174-40fb-a04c-e7cefd64a32f"
      },
      "source": [
        "frameNumber=0\n",
        "light=(0,0,255)\n",
        "while True:\n",
        "    #Reading frame from video\n",
        "    (check, frame1) = vs.read()\n",
        "    frameNumber+=1\n",
        "    if int(frameNumber/fps)==17:\n",
        "        print('Done 1')\n",
        "        light=(0,255,0)\n",
        "    elif int(frameNumber/fps)==20:\n",
        "        light=(0,0,255)\n",
        "    elif int(frameNumber/fps)==25:\n",
        "        print('Stop')\n",
        "        break\n",
        "    if not check:\n",
        "        break\n",
        "    frame=frame1.copy()\n",
        "    #Resizing Frame\n",
        "    frame = imutils.resize(frame, width=700)\n",
        "    #Extracting Results from the above function\n",
        "    results = detectFeatures(frame, net, ln,bicycleIndx=labels.index('bicycle'), carIndx=labels.index('car'), motorbikeIndx=labels.index('motorbike'), busIndx=labels.index('bus'), truckIndx=labels.index('truck'))\n",
        "    #Setting Number of Vehicles initially 0\n",
        "    vehicles=0\n",
        "    urgent=False\n",
        "    #Iterating through our results in Current frame\n",
        "    for (i,(prob, bbox, classID))in enumerate(results):\n",
        "        #Getting co-ordinates our current detection, and adding to corresponding Detection we got\n",
        "        (startX, startY, endX, endY)=bbox\n",
        "        if classID==labels.index('car') or classID==labels.index('bus') or classID==labels.index('truck'):\n",
        "            vehicles+=1\n",
        "            color=(0,255,0)\n",
        "            try:\n",
        "                vehicle=frame[startY:endY, startX:endX]\n",
        "                cv2.imwrite(tempPath,vehicle)\n",
        "                temp=open_image('/content/drive/MyDrive/Kaggle/Projects/EmergencyVehicleClassificationFastAI/1.jpg')\n",
        "                pred_class,pred_idx,outputs = emergencyModel.predict(temp)\n",
        "                if str(pred_class)=='1':\n",
        "                    color=(0,0,255)\n",
        "                    urgent=True\n",
        "                !rm -r '$tempPath'\n",
        "            except:\n",
        "                pass\n",
        "        elif classID==labels.index('bicycle') or classID==labels.index('motorbike'):\n",
        "            vehicles+=1\n",
        "            color=(0,255,0)\n",
        "        #Plotting rectangle around the detection and displaying what it is\n",
        "        cv2.rectangle(frame, (startX,startY),(endX,endY),color,1)\n",
        "        cv2.putText(frame, labels[classID], (startX,startY-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1)\n",
        "    #Displaying Summary of traffic on top-left\n",
        "    text1='Vehicles: {}'.format(vehicles)\n",
        "    text2='Emergency Vehicles: {}'.format(urgent)\n",
        "    cv2.putText(frame, text1, (25,frame.shape[0]-350),cv2.FONT_HERSHEY_SIMPLEX,0.6, (0,0,255),2)\n",
        "    cv2.putText(frame, text2, (25,frame.shape[0]-325),cv2.FONT_HERSHEY_SIMPLEX,0.6, (0,0,255),2)\n",
        "    cv2.rectangle(frame, (555,30),(640,90),(255,0,0), -1)\n",
        "    cv2.circle(frame, (600,60), 25, (0,0,255),-1)\n",
        "\n",
        "    #If display>0, you'll get to see each frame while it's being processed and written to Output file\n",
        "    if display>0:\n",
        "        cv2.imshow('Frame',frame)\n",
        "        key=cv2.waitKey(0)\n",
        "        if key==27:\n",
        "            break\n",
        "        cv2.destroyAllWindows()\n",
        "    if output!='' and writer is None:\n",
        "        fourcc=cv2.VideoWriter_fourcc(*'MJPG')\n",
        "        writer=cv2.VideoWriter(output, fourcc, fps, (frame.shape[1],frame.shape[0]))\n",
        "    if writer is not None:\n",
        "        writer.write(frame)\n",
        "writer.release()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Done 1\n",
            "Stop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNtEE19JXuwY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}